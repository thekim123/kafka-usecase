--- 
### 1. 영상 input 		
- **영상 저장**
	1. 원본 영상 bucket 저장 

- **비식별 처리** 
	1. input : 원본 영상
	2. output : 처리된 영상, endSequnce, {seq, [{coordinates}]}
		- ex
		``` json
		{
	  "sequence": [
	    {
	      "seq": 1,
	      "person": [
	        {
	          "x1": 100,
	          "x2": 200,
	          "y1": 150,
	          "y2": 250
	        },
	        {
	          "x1": 200,
	          "x2": 300,
	          "y1": 250,
	          "y2": 350
	        }
	      ]
	    },
	    {
	      "seq": 2,
	      "person": [
	        {
	          "x1": 120,
	          "x2": 220,
	          "y1": 160,
	          "y2": 260
	        }
	      ]
	    },
	    {
	      "seq": 3,
	      "person": [
	        {
	          "x1": 140,
	          "x2": 240,
	          "y1": 170,
	          "y2": 270
	        }
	      ]
	    }
	  ]
	}		
			```
			
		처리된 영상 : bucket에 저장
		endSequnce, {seq, [{coordinates}]} : db에 저장 (processedFrame Table)

※ *영상 처리 시 비디오 파일의 실제 총 프레임 개수를 정확히 확인 
	**정확한 영상 분할 및 타임라인 추출**: 영상 길이와 FPS를 정확히 활용하여 오차 없이 구현
```
[오차를 처리하는 방법]

>> 정확한 프레임 개수 가져오기 (FFmpeg)
	FFmpeg를 사용하면 비디오 파일의 실제 총 프레임 개수를 정확히 확인할 수 있습니다.
	ffprobe -v error -count_frames -select_streams v:0 -show_entries stream=nb_read_frames -of csv=p=0 your_video.mp4


>> OpenCV에서도 다음과 같이 총 프레임 개수를 확인할 수 있습니다.
	import cv2

	video_path = "your_video.mp4"
	cap = cv2.VideoCapture(video_path)

	# 총 프레임 수 가져오기
	total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
	fps = cap.get(cv2.CAP_PROP_FPS)
	duration = total_frames / fps

	print(f"Total Frames: {total_frames}, FPS: {fps}, Duration: {duration:.2f}s")
	cap.release()

>> 프레임과 시간을 매핑할 때 오차 보정
	# 특정 시간에 해당하는 프레임 번호를 계산할 때, 소수점 오차를 고려하여 보정하는 방법입니다.
	def time_to_frame(current_time, fps, total_frames):
	    estimated_frame = round(current_time * fps)
	    # 총 프레임 수를 넘지 않도록 제한
	    return min(estimated_frame, total_frames - 1)

>> 동영상 메타데이터와 프레임 간 불일치 처리
	- 슬라이더가 타임라인과 정확히 일치하도록, 비디오의 실제 총 프레임 수와 FPS 기반 계산값을 조정합니다.
	- 이 작업을 위해 슬라이더를 이동할 때마다 **가장 가까운 유효 프레임**으로 보정합니다.
```


--- 

### 2. 처리된 영상 보정 (편집)
- **WAS에서 `처리된 영상`과 `타임라인`, `좌표 데이터` 클라이언트에게 전송**

- **vue에서 `타임라인`을 슬라이더로 사용해 영상을 조작** 
	1. 타임라인 기반 슬라이더로 영상을 직관적으로 제어.
	2. 현재 재생 위치를 **시간**과 **프레임 번호**로 동적으로 계산

- **현재 위치에 HTML5 `<canvas>`를 사용해 프레임별로 모자이크 추가하거나 제외할 영역 생성** 
	- 타임라인 슬라이더로 특정 시간/프레임 이동
	- 특정 프레임에서 직사각형을 드래그하여 그리기
	- 각 프레임에 대해 직사각형의 좌표(x, y, width, height)를 저장
	- 모든 저장된 프레임 정보를 요청으로 전달
> **작동 방식**
		**타임라인 슬라이더 이동**:
		    - 슬라이더를 이동하면 `video.currentTime`이 업데이트되어 특정 시간/프레임으로 이동.
		**직사각형 드래그**:
		    - `mousedown`, `mousemove`, `mouseup` 이벤트로 캔버스에 직사각형을 드래그 및 표시.
		    - 드래그가 종료되면 현재 프레임 번호와 직사각형 좌표를 저장.
		**프레임별 데이터 저장**:
		    - 각 프레임에 대해 좌표(`x, y, width, height`)와 프레임 번호를 저장.
		**데이터 전송**:
		    - 저장된 데이터를 요청(`axios` 또는 `fetch`)으로 전송.

``` ex
	drawnRectangles: {
  		30: [{ x: 50, y: 50, width: 100, height: 100 }], // 프레임 30에서 그린 직사각형
  		90: [{ x: 120, y: 80, width: 150, height: 120 }], // 프레임 90에서 그린 직사각형
	}
```

- **생성된 `drawnRectangles`를 파라미터로 WAS에 보정 요청**
	1. python으로 변경된 프레임 seq와 좌표를 전달,
		-> 전체 영상이 아닌 `보정된 구간`만 모자이크 처리 수정 
	2. 최종 영상 반환 
		최종 처리된 영상을 bucket에 업로드


--- 

### 3. 최종 영상 반환 
		
